#!/usr/bin/env python3
"""
JT 3D PRINTING NEWS - Ollama News Extractor
Extrait les infos principales avec Ollama (Phi 3.8b par dÃ©faut)
"""

import requests
import json
import logging
import os
from typing import Dict
from dotenv import load_dotenv

load_dotenv()
logger = logging.getLogger(__name__)

class OllamaNewsExtractor:
    """Extrait infos d'une news avec Ollama Phi 3.8b"""
    
    def __init__(self, host: str = "http://localhost:11434", model: str = "phi3:3.8b"):
        """Initialise l'extracteur Ollama"""
        self.host = host
        # Le modÃ¨le par dÃ©faut est maintenant 'phi3:3.8b'
        self.model = model or os.getenv("OLLAMA_MODEL", "phi3:3.8b")
        self.api_url = f"{self.host}/api/generate"
        logger.info(f"ðŸ¤– Ollama Extractor initialized ({self.model})")
    
    def extract(self, article: Dict) -> Dict:
        """Extrait les infos principales d'un article"""
        
        logger.info(f"ðŸ“Š Analyzing: {article['title'][:50]}...")
        
        # Prompt pour extraction
        prompt = f"""Analyze this 3D printing news and extract key information.

Title: {article['title']}
Content: {article['content'][:500]}

Please provide:
1. Brief summary (2-3 sentences)
2. Key technical points (bullet list)
3. Market impact assessment
4. Relevance score (0-10)
5. Keywords (5-7)

Format JSON only."""
        
        try:
            # Timeout augmentÃ© Ã  300 secondes (5 minutes) pour le disque dur
            response = requests.post(
                self.api_url,
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "temperature": 0.7
                },
                timeout=300 
            )
            
            if response.status_code != 200:
                logger.error(f"âŒ Ollama error: {response.status_code}")
                return self._default_extraction(article)
            
            result = response.json()
            extracted_text = result.get("response", "")
            
            # Parse la rÃ©ponse
            extracted_info = self._parse_response(extracted_text)
            
            return {
                "title": article["title"],
                "source": article["source"],
                "summary": extracted_info.get("summary", ""),
                "technical_points": extracted_info.get("technical_points", []),
                "market_impact": extracted_info.get("market_impact", ""),
                "relevance_score": extracted_info.get("relevance_score", 5),
                "keywords": extracted_info.get("keywords", []),
                "angles": {
                    "technical": self._generate_angle(article, "technical"),
                    "market": self._generate_angle(article, "market"),
                    "business": self._generate_angle(article, "business")
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ Erreur Ollama: {e}")
            return self._default_extraction(article)
    
    def _parse_response(self, response_text: str) -> Dict:
        """Parse la rÃ©ponse Ollama"""
        try:
            # Essaye de parser JSON
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            if json_start >= 0 and json_end > json_start:
                json_str = response_text[json_start:json_end]
                return json.loads(json_str)
        except:
            pass
        
        # Fallback si pas JSON
        return {
            "summary": response_text[:200],
            "technical_points": [],
            "market_impact": "",
            "relevance_score": 5,
            "keywords": []
        }
    
    def _generate_angle(self, article: Dict, angle_type: str) -> str:
        """GÃ©nÃ¨re un angle diffÃ©rent pour l'article"""
        
        if angle_type == "technical":
            return f"Innovation technologique: {article['title']} reprÃ©sente une avancÃ©e en impression 3D..."
        elif angle_type == "market":
            return f"Impact marchÃ©: Cette annonce affecte le secteur de l'impression 3D avec potentiel de croissance..."
        else:  # business
            return f"Enjeux commerciaux: Pour les entreprises, cette innovation signifie opportunitÃ©s et dÃ©fis..."
    
    def _default_extraction(self, article: Dict) -> Dict:
        """Extraction par dÃ©faut si Ollama Ã©choue"""
        return {
            "title": article["title"],
            "source": article["source"],
            "summary": article["content"][:200],
            "technical_points": ["Impression 3D", "Innovation"],
            "market_impact": "Impact positif sur le marchÃ©",
            "relevance_score": 5,
            "keywords": ["3d printing", "innovation", "technology"],
            "angles": {
                "technical": "AvancÃ©e technologique en impression 3D",
                "market": "Impact sur le marchÃ© mondial",
                "business": "OpportunitÃ©s commerciales"
            }
        }


class OllamaLipSyncAnalyzer:
    """Analyse le texte pour gÃ©nÃ©rer lip-sync et gestes"""
    
    def __init__(self, host: str = "http://localhost:11434", model: str = "phi3:3.8b"):
        """Initialise l'analyseur lip-sync"""
        self.host = host
        self.model = model or os.getenv("OLLAMA_MODEL", "phi3:3.8b")
        self.api_url = f"{self.host}/api/generate"
    
    def analyze_for_animation(self, script_text: str) -> Dict:
        """Analyse le script pour animations et lip-sync"""
        
        prompt = f"""Analyze this TV script for animations and gestures.

Script: {script_text}

Provide:
1. Emotions detected
2. Suggested gestures (list)
3. Head movements (looking left/right/center)
4. Hand animations (if any)
5. Timing of key moments (in seconds)

Format as JSON."""
        
        try:
            response = requests.post(
                self.api_url,
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "temperature": 0.7
                },
                timeout=300 
            )
            
            if response.status_code == 200:
                result = response.json()
                return self._parse_animation_response(result.get("response", ""))
            
        except Exception as e:
            logger.warning(f"âš ï¸ Ollama animation analysis failed: {e}")
        
        # Fallback
        return {
            "emotions": ["neutral"],
            "gestures": [],
            "head_movements": "center",
            "hand_animations": [],
            "timing": {}
        }
    
    def _parse_animation_response(self, response_text: str) -> Dict:
        """Parse la rÃ©ponse animation Ollama"""
        try:
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            if json_start >= 0 and json_end > json_start:
                return json.loads(response_text[json_start:json_end])
        except:
            pass
        
        return {
            "emotions": ["neutral"],
            "gestures": [],
            "head_movements": "center",
            "hand_animations": [],
            "timing": {}
        }


def main():
    """Fonction de test"""
    test_article = {
        "title": "Prusa lance nouvelle imprimante rÃ©volutionnaire",
        "content": "Prusa vient de dÃ©voiler une imprimante 3D rÃ©volutionnaire...",
        "source": "3D Printing Industry"
    }
    
    extractor = OllamaNewsExtractor()
    extracted = extractor.extract(test_article)
    
    print("\nðŸ“Š EXTRACTED INFO:\n")
    print(json.dumps(extracted, indent=2, ensure_ascii=False))


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    main()
